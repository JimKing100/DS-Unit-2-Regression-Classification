{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "DSPT2_lesson_regression_classification_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JimKing100/DS-Unit-2-Regression-Classification/blob/master/DSPT2_lesson_regression_classification_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBMcrliJ0UWA",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Regression & Classification, Module 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP_QHa-Q0UWC",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmve7Rw70UWC",
        "colab_type": "text"
      },
      "source": [
        "#### If you're using [Anaconda](https://www.anaconda.com/distribution/) locally\n",
        "\n",
        "Install required Python packages, if you haven't already:\n",
        "- [category_encoders](http://contrib.scikit-learn.org/categorical-encoding/), version >= 2.0\n",
        "- [Plotly](https://plot.ly/python/getting-started/), version >= 4.0\n",
        "\n",
        "```\n",
        "conda install -c conda-forge category_encoders plotly\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-T3HbUZ0UWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python packages:\n",
        "    # category_encoders, version >= 2.0\n",
        "    # pandas-profiling, version >= 2.0\n",
        "    # plotly, version >= 4.0\n",
        "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_v4SKV60UWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R-SBzTd0UWI",
        "colab_type": "text"
      },
      "source": [
        "# Let's start with example solutions for yesterday's assignment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2GizMlE0UWI",
        "colab_type": "text"
      },
      "source": [
        "First, load data & remove outliers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnfqBhUX0UWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Read New York City apartment rental listing data\n",
        "df = pd.read_csv('../data/renthop-nyc.csv')\n",
        "assert df.shape == (49352, 34)\n",
        "\n",
        "# Remove the most extreme 1% prices,\n",
        "# the most extreme .1% latitudes, &\n",
        "# the most extreme .1% longitudes\n",
        "df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
        "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
        "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
        "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
        "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
        "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI1Wjv1p0UWL",
        "colab_type": "text"
      },
      "source": [
        "## Do train/test split\n",
        "- Use data from April & May 2016 to train\n",
        "- Use data from June 2016 to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lrMDTO50UWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to datetime and look at the date range\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wCBaH9h0UWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There are 16217 + 15627 observations in April & May 2016,\n",
        "# and 16973 observations in June 2016.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgmqEuj50UWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There are many ways to do train/test split based on date.\n",
        "# Here's one way:\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRk4RUDr0UWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's another way\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLv8wrnl0UWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's another way\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsBhN4XS0UWX",
        "colab_type": "text"
      },
      "source": [
        "## Location, Location, Location?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STxg_O2R0UWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at relationship between location & price\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ytS29030UWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cluster the locations\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abz3SI0o0UWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDGtTtCF4LDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6oiRJat4Yti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wuxrner0UWc",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory visualization for predictive modeling\n",
        "\n",
        "Visualize the relationships between feature(s) and target.\n",
        "\n",
        "_Recommendations:_\n",
        "\n",
        "Do this with your training set, after splitting your data. \n",
        "\n",
        "Try [Seaborn \"Categorical estimate\" plots](https://seaborn.pydata.org/tutorial/categorical.html) for features with reasonably few unique values. (With too many unique values, the plot is unreadable.)\n",
        "\n",
        "- Categorical features. (If there are too many unique values, you can replace less frequent values with \"OTHER.\")\n",
        "- Numeric features. (If there are too many unique values, you can [bin with pandas cut / qcut functions](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=qcut#discretization-and-quantiling).)\n",
        "\n",
        "Try [Seaborn linear model plots](https://seaborn.pydata.org/tutorial/regression.html) with numeric features.\n",
        "\n",
        "Seaborn is nice because it includes confidence intervals to visualize uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn3wjS617tF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0RS6L3B8FD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcxRYsSc-3JU",
        "colab_type": "text"
      },
      "source": [
        "If you wanted to do t test: \n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "cat1 = my_data[my_data['Category']=='cat1']\n",
        "cat2 = my_data[my_data['Category']=='cat2']\n",
        "\n",
        "ttest_ind(cat1['values'], cat2['values'])\n",
        "\n",
        "Returns t statistics, then p-value. (1.4927289925706944, 0.16970867501294376)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AspZY3hs0UWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mqRhaoH-Abv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaO89xtd0UWe",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDJTJpPl0UWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiX6c09t0UWg",
        "colab_type": "text"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIcjv5Kx0UWh",
        "colab_type": "text"
      },
      "source": [
        "The previous assignment quoted Wikipedia on [Feature Engineering](https://en.wikipedia.org/wiki/Feature_engineering):\n",
        "\n",
        "> \"Some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used.\" — Pedro Domingos, [\"A Few Useful Things to Know about Machine Learning\"](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
        "\n",
        "> \"Coming up with features is difficult, time-consuming, requires expert knowledge. 'Applied machine learning' is basically feature engineering.\" — Andrew Ng, [Machine Learning and AI via Brain simulations](https://forum.stanford.edu/events/2011/2011slides/plenary/2011plenaryNg.pdf) \n",
        "\n",
        "> Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. \n",
        "\n",
        "Pedro Domingos says, \"the most important factor is the **features used**.\"\n",
        "\n",
        "This includes not just **Feature Engineering** (making new features, representing features in new ways) but also **Feature Selection** (choosing which features to include and which to exclude).\n",
        "\n",
        "There are _many_ specific tools and techniques for feature selection.\n",
        "\n",
        "- Today we'll try [scikit-learn's `SelectKBest` transformer](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection), for \"univariate, forward selection.\"\n",
        "- Next week we'll try another technique, [\"permutation importance\"](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "- If you want to explore even more options, here are some good resources!\n",
        "  - [scikit-learn's User Guide for Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "  - [mlxtend](http://rasbt.github.io/mlxtend/) library\n",
        "  - scikit-learn-contrib libraries: [boruta_py](https://github.com/scikit-learn-contrib/boruta_py) & [stability-selection](https://github.com/scikit-learn-contrib/stability-selection)\n",
        "  - [_Feature Engineering and Selection_](http://www.feat.engineering/) by Kuhn & Johnson.\n",
        "\n",
        "\n",
        "My general recommendation is:\n",
        "\n",
        "> Predictive accuracy on test sets is the criterion for how good the model is. — Leo Breiman, [\"Statistical Modeling: The Two Cultures\"](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBKy0Zzi0UWh",
        "colab_type": "text"
      },
      "source": [
        "### Can we try every possible feature combination?\n",
        "- https://en.wikipedia.org/wiki/Combination\n",
        "- https://docs.python.org/3/library/itertools.html#itertools.combinations\n",
        "- https://docs.python.org/3/library/math.html#math.factorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4sFHW5v0UWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many features do we have currently?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnfzNVmc0UWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many ways to choose 1 feature?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjQTR2I00UWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many ways to choose 2 features?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxwE2mto0UWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many ways to choose 3 features?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLPVb0510UWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many ways to choose 1 to n features?\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TwakmBi0UWs",
        "colab_type": "text"
      },
      "source": [
        "### Start simple & fast, with a subset of columns\n",
        "\n",
        "Just numeric columns with no missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7dGWjD-0UWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a5hRDlu0UWv",
        "colab_type": "text"
      },
      "source": [
        "### Univariate, Forward selection\n",
        "https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eX6foc10UWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XScXvwuKTS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Which features were selected?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOVK-HqfLOz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOSqd2KOLmen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yHOmHvG0UWw",
        "colab_type": "text"
      },
      "source": [
        "## Do one-hot encoding of categorical features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyImpIPW0UWx",
        "colab_type": "text"
      },
      "source": [
        "### Which features are non-numeric?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQRQcpliM__f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uoov0rY0UWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice that fitness center was a numeric encoding of a categorical feature\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKMRfnE3NNrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t25PK1h8M-aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf_QH_dJ0UWz",
        "colab_type": "text"
      },
      "source": [
        "### Check \"cardinality\" of non-numeric features\n",
        "\n",
        "[Cardinality](https://simple.wikipedia.org/wiki/Cardinality) means the number of unique values that a feature has:\n",
        "> In mathematics, the cardinality of a set means the number of its elements. For example, the set A = {2, 4, 6} contains 3 elements, and therefore A has a cardinality of 3. \n",
        "\n",
        "\"One-hot encoding\" adds a dimension for each unique value of each categorical feature. So, it may not be a good choice for \"high cardinality\" categoricals that have dozens, hundreds, or thousands of unique values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc3qW8sX0UWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkSaVOp8OTsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mLfEvRQ0UW0",
        "colab_type": "text"
      },
      "source": [
        "### Explore `interest_level` feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLn3mhZ-0UW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecopnCWGOp1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCiuJLs1Owkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at interest level for first 5 apartments\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqePupnU0UW2",
        "colab_type": "text"
      },
      "source": [
        "### Encode `interest_level` feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN1XakA80UW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at interest level for first 5 apartments, one-hot encoded\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHJoKTeI0UW4",
        "colab_type": "text"
      },
      "source": [
        "## Do one-hot encoding & Scale features, \n",
        "within a complete model fitting workflow.\n",
        "\n",
        "### Why and how to scale features before fitting linear models\n",
        "\n",
        "Scikit-Learn User Guide, [Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
        "> Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
        "\n",
        "> The `preprocessing` module further provides a utility class `StandardScaler` that implements the `Transformer` API to compute the mean and standard deviation on a training set. The scaler instance can then be used on new data to transform it the same way it did on the training set.\n",
        "\n",
        "### How to use encoders and scalers in scikit-learn\n",
        "- Use the **`fit_transform`** method on the **train** set\n",
        "- Use the **`transform`** method on the **validation / test** sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhKrndVX0UW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAf34kSyQmG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}